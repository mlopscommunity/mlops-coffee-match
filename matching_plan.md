# Matching System Plan

## 1. High-Level Matching Strategy

- **Goal**: Create fair, high-quality, and well-justified 1:1 matches for virtual coffee participants.
- **Core Approach**: An iterative, agent-based system that prioritizes members with specific constraints and uses a hybrid search mechanism to find the best possible buddy for each person sequentially. The system will be followed by a global optimization pass to improve lower-quality pairings.

## 2. Data Preparation and Feature Engineering

- **Strategy**: Prioritize a lightweight, LLM-centric approach over heavy data cleaning.
- **Function for Location Normalization**: Implement a dedicated function that uses a small, constrained LLM to map raw `location` strings to a standardized list of regions. This will create a new, clean categorical feature for filtering.
- **Two-Vector Embedding Strategy**: Instead of embedding all text fields separately, create two distinct semantic vectors for each participant:
  - **`profile_embedding`**: Generated by combining the `summary` and `skills` fields into a single text block. This vector represents what a person *is*.
  - **`preference_embedding`**: Generated from the `buddy_preferences` text. This vector represents what a person *wants*.
- **Rationale**: This approach allows for a more precise similarity search, where we can directly compare a "Seeker's" `preference_embedding` against a "Candidate's" `profile_embedding`.

## 3. Scoring and Matching Algorithm

- **Initialization**:
  - Load all participants into a single DataFrame.
  - Sort the DataFrame by `buddy_preference` to create a processing queue that places participants with hard constraints at the top.
- **Core Agentic Loop**:
  - For each person (the "Seeker") in the sorted queue:
    1.  **Invoke LLM Agent**: The agent receives the Seeker's profile and access to a powerful `find_best_matches` tool.
    2.  **Hybrid Search**: The agent uses the tool to get a top-10 list of candidates. The tool combines:
        -   **Hard Filters**: Mandatory criteria from the Seeker's `buddy_preference`.
        -   **Semantic Similarity**: A vector search comparing the Seeker's `preference_embedding` against the `profile_embedding` of potential candidates.
    3.  **Final Selection & Justification**: The agent reasons over the top-10 list, selects the single best buddy, and generates a structured response with the match's ID and a justification/icebreaker.
    4.  **Update Pool**: The Seeker and their chosen buddy are paired and removed from the pool of available participants. The agent's context is reset for the next iteration.
- **Handling Leftovers**: If one person remains at the end, they are added to the most recently formed pair to create a group of three.

## 4. Post-Match Review and Optimization

- **LLM-as-a-Judge Review**: After the initial matching pass is complete, use a separate LLM call to perform a qualitative review.
  - **Batch Processing**: The generated pairs and their justifications will be sent to the "judge" LLM in batches (e.g., a dozen at a time).
  - **Critical Evaluation**: The judge will be prompted to identify any matches that seem weak, illogical, or have poor justifications, and to flag them for re-matching.
- **Re-assignment**:
  - All individuals from the flagged pairs will be collected into a new, smaller pool.
  - The core matching algorithm will be run again on this small pool to find better assignments for them.
- **Finalization**: The re-matched pairs are integrated back into the main list, and the final assignments are saved.

## 5. Match Storage and Feedback Loop

- **Match Schema**: Define a structure to store final pairings, match scores, and the LLM-generated justification.
- **Feedback Tracking**: Include fields for status (e.g., `met`, `cancelled`, `no-show`) and qualitative participant feedback to inform future matching rounds.

## 6. Implementation Plan & Tooling

- **Project Structure**:
  - Create a new `matching/` directory to house all logic for the recommendation system, separating it from `synthetic_generation/`.
  - Key modules will include `data_models.py`, `feature_engineering.py`, `agent.py`, and a `main.py` for the CLI.
- **Core Libraries**:
  - **Data Handling**: `pandas` will be used to manage the participant data, including storing the generated embeddings as new columns.
  - **Vector Search**: No vector database is needed. The hybrid search tool will be implemented in-memory by chaining two steps: first, using `pandas` to apply any hard filters (like `role`) to create a temporary, smaller DataFrame of eligible candidates. Second, running `scikit-learn`'s `cosine_similarity` *only* on this pre-filtered subset, ensuring an efficient and combined ranking process.
  - **LLM Interaction**: The lightweight `openai` library will be used for both generating embeddings and for the agent's tool-calling capabilities.
  - **CLI**: A simple CLI will be built using `Typer` to make the matching process easy to run and configure.
- **Output Format**:
  - The final matches will be saved to a CSV file (`matches.csv`) for maximum compatibility with spreadsheet tools like Google Sheets.
  - The CSV will have columns for `participant_A_id`, `participant_B_id`, `llm_justification`, `match_score`, and feedback tracking columns.
